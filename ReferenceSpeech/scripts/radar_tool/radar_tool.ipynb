{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c6ca259",
   "metadata": {},
   "source": [
    "# 1. Experiements towards reference speech characterization\n",
    "\n",
    "The following cells import the necessary functions, and define the code to run the experiments. Update the paths in the cell bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/path/to/ReferenceSpeech/\" # UPDATE THIS!\n",
    "\n",
    "# output_dir: used to save results and configs.\n",
    "MAIN_OUTPUT_DIR = ROOT + \"/results/\" # UPDATE THIS!\n",
    "\n",
    "print (\"Let's get started!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import json\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "SEED=741\n",
    "np.random.seed(seed=SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3666f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.speech_model import SpeechModel             # speech model class\n",
    "from utils.outlier_removal import OutlierRemoval       # outlier removal\n",
    "from utils.reference_intervals import RefIntEstimator  # class for defining reference interval\n",
    "from utils.mannwhitheyu import feats_failling_mwut     # functions for mann-whitney U test (partition reference population)\n",
    "from utils.io import *                                 # Function for loading data\n",
    "from utils.scale import *                              # scale/normalization functions\n",
    "from utils.plots import *                              # function to creatre the radar plot, and other plots\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bdb32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run one experiment:\n",
    "\n",
    "def experiment(\n",
    "    ref_speech_model, control_config, disease_configs,\n",
    "    disease_names, features_by_task, features_to_drop=[],\n",
    "    norm_strat=\"none\", ref_scaler=None):\n",
    "    \"\"\"\n",
    "    : ref speech model\n",
    "    : control config\n",
    "    : disease_configs (list of configs)\n",
    "    : disease names (useful for image captions)\n",
    "    : features to drop (list of features to exclude, e.g. because they have invalid intervals)\n",
    "    : features_by_task (mapping of features to tasks)\n",
    "    : norm_strat (string) It accepts {\"none\", \"control_scaler\", \"ref_scaler\"}.\n",
    "        <control_scaler> means that controls will be used to train the scaler\n",
    "        <ref_scaler> means that scaler from ref model is be used. \n",
    "    : ref_scaler\n",
    "    \"\"\"\n",
    "    color_lst = [\"blue\", \"magenta\", \"orange\", \"red\"]\n",
    "    \n",
    "    # create control model\n",
    "    print (\"[INFO]: Getting model for controls ...\")\n",
    "    control_model = SpeechModel(control_config)\n",
    "    _ = control_model.transform_feats_df_by_task(\n",
    "        features_by_task, drop_features=features_to_drop)\n",
    "    \n",
    "    # normalize data:\n",
    "    assert norm_strat in [\"none\", \"control_scaler\", \"ref_scaler\"]\n",
    "    if norm_strat == \"control_scaler\":\n",
    "        control_model.normalize(pretrained_scaler=None, train_scaler=True)\n",
    "        control_scaler = control_model.scaler\n",
    "    elif norm_strat == \"ref_scaler\":\n",
    "        assert ref_scaler is not None, \"if norm_strat is set to 'ref_scaler', ref_scaler cannot be None.\"\n",
    "        control_model.normalize(pretrained_scaler=ref_scaler, train_scaler=False)\n",
    "            \n",
    "    # get RI dataframe\n",
    "    ri_df = ref_speech_model.ri_df.copy()\n",
    "    control_model.ri_df = ri_df\n",
    "    ri_df[\"keep_feature\"] = True\n",
    "    \n",
    "    # list features to be analysed\n",
    "    features_to_include = [\n",
    "        f \n",
    "        for f in ri_df[ri_df.keep_feature].feature.values \n",
    "        if f not in features_to_drop]\n",
    "\n",
    "    # are control values inside RI?\n",
    "    control_feats_vs_ri_df = control_model.are_individual_feats_in_ri(\n",
    "        control_model.feats_df,\n",
    "        feature_names=features_to_include,\n",
    "        friendly_summary=False) \n",
    "    control_feats_vs_ri_df = control_feats_vs_ri_df[\n",
    "            control_feats_vs_ri_df.n_non_nan_samples > 0\n",
    "        ][[\"feature\", \"prop_out_ri_over_subgroup\"]]\n",
    "\n",
    "    # count number of features in RI per control subject\n",
    "    feats_in_ri_per_control_subj = control_model.count_feats_out_ri(\n",
    "        control_model.feats_df, \n",
    "        feature_names=features_to_include)\n",
    "    \n",
    "    # Summary for control subjects\n",
    "    print()\n",
    "    print (\"*** SUMMARY FOR CONTROLS ***\")\n",
    "    print (\"number of features\", len(control_feats_vs_ri_df))\n",
    "\n",
    "    print(len(feats_in_ri_per_control_subj[feats_in_ri_per_control_subj.n_feats_out < 1]), \n",
    "          \"indiv with 0 feats out ri, out of\",\n",
    "          len(feats_in_ri_per_control_subj),\n",
    "          \"subjects. i.e, a proportion of\", \n",
    "          len(feats_in_ri_per_control_subj[feats_in_ri_per_control_subj.n_feats_out < 1])/len(feats_in_ri_per_control_subj),\n",
    "         )\n",
    "    \n",
    "    print ()\n",
    "    print(\"Average number of features outside RI:\", \n",
    "          np.mean(feats_in_ri_per_control_subj.n_feats_out.values))\n",
    "    print(\"Average number of features larger than RI:\", \n",
    "          np.mean(feats_in_ri_per_control_subj.n_feats_over_upperlimit.values))\n",
    "    print(\"Average number of features smaller than RI:\", \n",
    "          np.mean(feats_in_ri_per_control_subj.n_feats_below_lowerlimit.values))\n",
    "    \n",
    "    # Make radar plot:\n",
    "    fig_f = clear_plot(ref_speech_model)\n",
    "    plotted_vals = control_model.add_trace_to_radar_plot(to_plot=\"all\", line_opacity=0.1, \n",
    "            fig=fig_f, \n",
    "            original_plot_feature_names=ref_speech_model.feature_names_lst,\n",
    "            legend_prefix=\"control\", save_fig=False,\n",
    "            color=color_lst[0])\n",
    "    \n",
    "    # EXPLORE DISEASE POPULATION:\n",
    "    feats_vs_ri_lst = [control_feats_vs_ri_df]\n",
    "    feats_in_ri_per_subj_lst = [feats_in_ri_per_control_subj]\n",
    "    disease_models = []\n",
    "    for i, c in enumerate(disease_configs):\n",
    "\n",
    "        # create disease model\n",
    "        print (\"[INFO]: Getting model for disease \", disease_names[i])\n",
    "        disease_model = SpeechModel(c)\n",
    "        _ = disease_model.transform_feats_df_by_task(features_by_task, drop_features=features_to_drop)\n",
    "        \n",
    "        # normalize data\n",
    "        if norm_strat == \"control_scaler\":\n",
    "            disease_model.normalize(pretrained_scaler=control_scaler, train_scaler=False)\n",
    "        elif norm_strat == \"ref_scaler\":\n",
    "            disease_model.normalize(pretrained_scaler=ref_scaler, train_scaler=False)\n",
    "            \n",
    "        # are features inside RI?\n",
    "        disease_feats_vs_ri_df = control_model.are_individual_feats_in_ri(\n",
    "            disease_model.feats_df,\n",
    "            feature_names=features_to_include,\n",
    "            friendly_summary=False,\n",
    "            mode=\"inside_ri\") \n",
    "\n",
    "        feats_in_ri_per_d_subject = control_model.count_feats_out_ri(\n",
    "            disease_model.feats_df, feature_names=features_to_include)\n",
    "        \n",
    "        # store relevant info:\n",
    "        feats_vs_ri_lst.append(disease_feats_vs_ri_df)\n",
    "        feats_in_ri_per_subj_lst.append(feats_in_ri_per_d_subject)\n",
    "        disease_models.append(disease_model)\n",
    "        \n",
    "        # Summary for control subjects\n",
    "        print()\n",
    "        print (\"*** SUMMARY FOR DISEASE \", disease_names[i] ,\" ***\")\n",
    "        print(len(feats_in_ri_per_d_subject[feats_in_ri_per_d_subject.n_feats_out < 1]), \n",
    "              \"indiv with 0 feats out ri, out of\",\n",
    "              len(feats_in_ri_per_d_subject),\n",
    "              \"subjects. i.e, a proportion of\",\n",
    "              len(feats_in_ri_per_d_subject[feats_in_ri_per_d_subject.n_feats_out < 1])/len(feats_in_ri_per_d_subject),\n",
    "             )\n",
    "\n",
    "        print(\"Average number of features outside RI:\",\n",
    "              np.mean(feats_in_ri_per_d_subject.n_feats_out.values))\n",
    "        print(\"Average number of features larger than RI:\", np.mean(feats_in_ri_per_d_subject.n_feats_over_upperlimit.values))\n",
    "        print(\"Average number of features smaller than RI:\", np.mean(feats_in_ri_per_d_subject.n_feats_below_lowerlimit.values))\n",
    "\n",
    "        \n",
    "        # Make radar plot:\n",
    "        fig_f = clear_plot(ref_speech_model)\n",
    "        _ = disease_model.add_trace_to_radar_plot(to_plot=\"all\", line_opacity=0.1, \n",
    "                fig=fig_f, \n",
    "                original_plot_feature_names=ref_speech_model.feature_names_lst,\n",
    "                legend_prefix=\"control\", save_fig=False,\n",
    "                color=color_lst[i+1])\n",
    "    \n",
    "    # print table with feature summary\n",
    "    for i, (disease, d_df) in enumerate(zip(disease_names, feats_vs_ri_lst[1:])):\n",
    "    \n",
    "        if i==0:\n",
    "            # merge controls and dementia\n",
    "            summary_df = pd.merge(\n",
    "                control_feats_vs_ri_df[[\"feature\", \"prop_out_ri_over_subgroup\"]], \n",
    "                d_df[[\"feature\", \"prop_out_ri_over_subgroup\"]], \n",
    "                on=\"feature\", \n",
    "                suffixes=(\"#Cont\", \"#\" + disease))\n",
    "        else:\n",
    "            # merge\n",
    "            tmp_df = d_df[[\"feature\", \"prop_out_ri_over_subgroup\"]]\n",
    "            tmp_df = tmp_df.rename(columns={\"prop_out_ri_over_subgroup\": \"prop_out_ri_over_subgroup#\" + disease})\n",
    "            summary_df = pd.merge(summary_df, tmp_df, on=\"feature\")\n",
    "\n",
    "    print (\"[INFO]: Done! :) \")\n",
    "    return summary_df, control_model, disease_models\n",
    "\n",
    "\n",
    "def clear_plot(ref_model):\n",
    "    fig_f = ref_model.build_radar_plot(\n",
    "        plot_mean=True, save_fig=False,\n",
    "        plot_ri=True, mean_color=\"green\")\n",
    "    return fig_f   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b98bba",
   "metadata": {},
   "source": [
    "# 2. Configurations \n",
    "\n",
    "Here we organize feature names, features that will be excluded because they may have failed some tests, and mappings between features and tasks. Notice that although we define *excluded_due_to_read_speech_test* and *invalid_intervals* here, they result from design exploration experiments described below in sections 4. and 5.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = {\n",
    "    \"linguistic\": [\n",
    "        \"content_density\", \"idea_density\", \"honore_statistic\", \"brunet_index\", \"type_token_ratio\",\n",
    "        \"discourse_marker_rate\", \n",
    "        \"polarity\", \n",
    "        \"repeat_ratio\",\n",
    "        \"mean_coher_sentence\",\"variability_coher_sentence\",\"mean_coher_14tokens\",\"variability_coher_14tokens\",\n",
    "        \"1st_pronouns_ratio\",\n",
    "        \"ambiguous_ref_ratio\",\"ref_chain_ratio\"\n",
    "        ],\n",
    "    \"praat\": [\n",
    "        \"meanF0\",\"stdevF0\",\"minF0\",\"maxF0\",\"hnr\",\n",
    "        \"localJitter\",\"localabsoluteJitter\",\"rapJitter\",\"ppq5Jitter\",\"ddpJitter\",\n",
    "        \"localShimmer\",\"localdbShimmer\",\"apq3Shimmer\",\"aqpq5Shimmer\",\"apq11Shimmer\",\"ddaShimmer\",\n",
    "        \"f1_mean\",\"f2_mean\",\"f3_mean\",\"f4_mean\",\"f1_median\",\"f2_median\",\"f3_median\",\"f4_median\",\n",
    "\n",
    "        \"speechrate(nsyll / dur)\",\"articulation rate(nsyll / phonationtime)\",\"ASD(speakingtime / nsyll)\",\n",
    "         \"mean_pause_dur\",\"mean_speech_dur\",\"silence_rate (silencetime/dur)\",\"silence_speech_ratio\",\"mean_sil_count\",\"lsil_rate\",\"lsil_speech_ratio\",\"mean_lsil_count\"\n",
    "        ],\n",
    "    \"egemaps\": [\n",
    "        \"F0semitoneFrom27.5Hz_sma3nz_amean\", \"F0semitoneFrom27.5Hz_sma3nz_stddevNorm\", \"F0semitoneFrom27.5Hz_sma3nz_percentile20.0\", \n",
    "        \"F0semitoneFrom27.5Hz_sma3nz_percentile50.0\", \n",
    "        \"F0semitoneFrom27.5Hz_sma3nz_percentile80.0\", \"F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2\",\n",
    "        \"F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope\", \n",
    "        \"F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope\", \"F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope\", \n",
    "        \"F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope\",\n",
    "\n",
    "        \"HNRdBACF_sma3nz_amean\", \"HNRdBACF_sma3nz_stddevNorm\",\n",
    "        \"jitterLocal_sma3nz_amean\", \"jitterLocal_sma3nz_stddevNorm\", \"shimmerLocaldB_sma3nz_amean\", \"shimmerLocaldB_sma3nz_stddevNorm\", \n",
    "\n",
    "        \"F1frequency_sma3nz_amean\", \"F1frequency_sma3nz_stddevNorm\", \"F1bandwidth_sma3nz_amean\", \"F1bandwidth_sma3nz_stddevNorm\",\n",
    "        \"F2frequency_sma3nz_amean\", \"F2frequency_sma3nz_stddevNorm\", \"F2bandwidth_sma3nz_amean\",\"F2bandwidth_sma3nz_stddevNorm\",\n",
    "        \"F3frequency_sma3nz_amean\", \"F3frequency_sma3nz_stddevNorm\", \"F3bandwidth_sma3nz_amean\",\"F3bandwidth_sma3nz_stddevNorm\",\n",
    "\n",
    "        \"loudnessPeaksPerSec\", \"VoicedSegmentsPerSec\", \"MeanVoicedSegmentLengthSec\", \"StddevVoicedSegmentLengthSec\", \"MeanUnvoicedSegmentLength\", \"StddevUnvoicedSegmentLength\"\n",
    "        ],\n",
    "    \"rythm_features\": [\n",
    "        \"speechrate(nsyll / dur)\",\"articulation rate(nsyll / phonationtime)\",\n",
    "        \"ASD(speakingtime / nsyll)\",\n",
    "        \"mean_pause_dur\",\"mean_speech_dur\",\"silence_rate (silencetime/dur)\",\n",
    "        \"silence_speech_ratio\",\"mean_sil_count\",\"lsil_rate\",\n",
    "        \"lsil_speech_ratio\",\"mean_lsil_count\",\n",
    "        \"loudnessPeaksPerSec\", \"VoicedSegmentsPerSec\", \"MeanVoicedSegmentLengthSec\", \"StddevVoicedSegmentLengthSec\", \n",
    "        \"MeanUnvoicedSegmentLength\", \"StddevUnvoicedSegmentLength\"\n",
    "        ],\n",
    "    \"for_outlier_detect\": ['F0semitoneFrom27.5Hz_sma3nz_amean_foroutlierdetect', 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm_foroutlierdetect',\n",
    "         'F0semitoneFrom27.5Hz_sma3nz_percentile20.0_foroutlierdetect', 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0_foroutlierdetect',\n",
    "         'F0semitoneFrom27.5Hz_sma3nz_percentile80.0_foroutlierdetect', 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2_foroutlierdetect',\n",
    "         'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope_foroutlierdetect', 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope_foroutlierdetect',\n",
    "         'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope_foroutlierdetect', 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope_foroutlierdetect',\n",
    "         'HNRdBACF_sma3nz_amean_foroutlierdetect', 'HNRdBACF_sma3nz_stddevNorm_foroutlierdetect',  'jitterLocal_sma3nz_amean_foroutlierdetect',\n",
    "         'jitterLocal_sma3nz_stddevNorm_foroutlierdetect', 'shimmerLocaldB_sma3nz_amean_foroutlierdetect', 'shimmerLocaldB_sma3nz_stddevNorm_foroutlierdetect',\n",
    "         'F1frequency_sma3nz_amean_foroutlierdetect', 'F1frequency_sma3nz_stddevNorm_foroutlierdetect', 'F1bandwidth_sma3nz_amean_foroutlierdetect',\n",
    "         'F1bandwidth_sma3nz_stddevNorm_foroutlierdetect', 'F2frequency_sma3nz_amean_foroutlierdetect', 'F2frequency_sma3nz_stddevNorm_foroutlierdetect',\n",
    "         'F2bandwidth_sma3nz_amean_foroutlierdetect', 'F2bandwidth_sma3nz_stddevNorm_foroutlierdetect', 'F3frequency_sma3nz_amean_foroutlierdetect', \n",
    "         'F3frequency_sma3nz_stddevNorm_foroutlierdetect', 'F3bandwidth_sma3nz_amean_foroutlierdetect', 'F3bandwidth_sma3nz_stddevNorm_foroutlierdetect',\n",
    "         'loudnessPeaksPerSec_foroutlierdetect', 'VoicedSegmentsPerSec_foroutlierdetect', 'MeanVoicedSegmentLengthSec_foroutlierdetect', 'StddevVoicedSegmentLengthSec_foroutlierdetect',\n",
    "         'MeanUnvoicedSegmentLength_foroutlierdetect', 'StddevUnvoicedSegmentLength_foroutlierdetect'\n",
    "        ],\n",
    "    \"excluded_due_to_read_speech_test\": ['lsil_rate', 'lsil_speech_ratio', 'maxF0', 'mean_lsil_count', 'minF0'],\n",
    "                                         \n",
    "    \"invalid_intervals\": ['A#F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
    "       'A#F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
    "       'A#F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
    "       'A#F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
    "       'A#F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
    "       'A#HNRdBACF_sma3nz_amean', 'A#HNRdBACF_sma3nz_stddevNorm',\n",
    "       'A#localabsoluteJitter', 'A#ppq5Jitter',\n",
    "       'Pic#F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
    "       'Pic#ambiguous_ref_ratio', 'Pic#discourse_marker_rate'\n",
    "       ],\n",
    "}         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb292b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's organize the features by task:\n",
    "\n",
    "FEATURES_BY_TASK = {\n",
    "        \n",
    "    \"vowel_a\": add_del_lst(add=[FEATURE_NAMES[\"egemaps\"], FEATURE_NAMES[\"praat\"]],\n",
    "                          subtract=[FEATURE_NAMES[\"rythm_features\"]]),\n",
    "    \n",
    "    \"read_speech\": add_del_lst(\n",
    "        add=[FEATURE_NAMES[\"egemaps\"], FEATURE_NAMES[\"praat\"]], \n",
    "        subtract=[FEATURE_NAMES[\"excluded_due_to_read_speech_test\"]]),\n",
    "    \n",
    "    \"spont_speech_interview\": add_del_lst( \n",
    "        add=[FEATURE_NAMES[\"egemaps\"], FEATURE_NAMES[\"praat\"]], \n",
    "        subtract=[FEATURE_NAMES[\"excluded_due_to_read_speech_test\"]]),\n",
    "    \n",
    "    \"spont_speech_picture\":  add_del_lst( \n",
    "        add=[FEATURE_NAMES[\"egemaps\"], FEATURE_NAMES[\"praat\"], FEATURE_NAMES[\"linguistic\"]], \n",
    "        subtract=[FEATURE_NAMES[\"excluded_due_to_read_speech_test\"]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560c2251",
   "metadata": {},
   "source": [
    "# 3. Outlier removal\n",
    "\n",
    "Outlier removal is a very important step prior to the definition of reference intervals. The outlier estimation strategy chosen was the mahalanobis distance + MDC for covariance estimator, and IQR for threshold definition. Mahalanobis works well for multivariate data.\n",
    "\n",
    "We opted to use only egemaps-based features for the outlier removal. We excluded praat features because there was too much dependency with egemaps features, and the matrix was not full rank. We excluded linguistic features because they were not meaningfull for read speech (no variance for the same texts).\n",
    "\n",
    "Normalization of the datasets is expected to impact the results of outlier estimation, but it is rarely discussed in the literature, and there are no clear guidelines of which normalization method works best for each outlier removal strategy.\n",
    "For this reason, and the fact that the mahalanobis distance should be robust to different scales, we decided not to perform normalization prior to the outlier removal. We only normalize it to fit the pca, for better data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8318c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Determine outliers and FOR SENTENCES\n",
    "\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"/outlier_removal_sentence/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "reference_config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\", \"voxceleb_annotated_usa_concatenated\", \"timit_concatenated\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\", #\"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"pic_description\", \"read_speech\", \"concat_interview_segm\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": False,\n",
    "        \"outlier_id_list\": None,\n",
    "        \"method\": \"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\",\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "            \n",
    "    # normalization -> we are not yet normalizing.\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": None, #\"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": False,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "reference_speech_model = SpeechModel(reference_config)\n",
    "sentence_outliers = reference_speech_model.meta_df[reference_speech_model.meta_df.outlier == True].wav_file_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine outliers and FOR VOWELS\n",
    "\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"/outlier_removal_vowel/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "reference_vowels_config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\", \"voxceleb_annotated_usa_concatenated\", \"timit_concatenated\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\", #\"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"vowel_a\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": False,\n",
    "        \"outlier_id_list\": None,\n",
    "        \"method\": \"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\",\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True, #False\n",
    "            \n",
    "    # normalization -> we are not yet normalizing.\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": None, #\"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": False,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "reference_speech_model = SpeechModel(reference_vowels_config)\n",
    "vowel_outliers = reference_speech_model.meta_df[reference_speech_model.meta_df.outlier == True].wav_file_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351a5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_ids = vowel_outliers.tolist() + sentence_outliers.tolist()\n",
    "print (\"In total, \", len(outlier_ids), \"outliers were detected, and will be excluded from further analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a1dd6",
   "metadata": {},
   "source": [
    "# 4. When  should we partition the reference population, and derive distinct reference intervals?\n",
    "\n",
    "Because the features used are affected not only by speech affecting diseases but also other factors, such as demographics and speech tasks, here we explore whether we should partition the reference population and derive distinct Reference Intervals for several factors: gender, age range, speech task, corpus, and normalized corpus.\n",
    "\n",
    "If you are not interested in this section, you may skip directlty to section 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29f8fb",
   "metadata": {},
   "source": [
    "### Explore gender\n",
    "- Using Mann-Whitney U test\n",
    "- Using the corpus CLAC and the speech task picture_description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize read speech model:\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"partitioning/gender/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\", #\"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"pic_description\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None, #\"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "            \n",
    "    # normalization\n",
    "    \"scale\": True,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "speech_model = SpeechModel(config)\n",
    "\n",
    "\n",
    "# Get features and metadata:\n",
    "feats_names = speech_model.feature_names_lst\n",
    "meta = speech_model.meta_df.copy()\n",
    "feats = speech_model.feats_df.copy()\n",
    "\n",
    "\n",
    "# Run Mann-Whitney U test\n",
    "print (\" ------------ ANALYSIS USING ALL DATA  ------------\")\n",
    "features_that_should_have_distinct_ris = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"gender\": [\"female\"]}, {\"gender\": [\"male\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names) )\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris),\n",
    "    \"features.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9298da1",
   "metadata": {},
   "source": [
    "### Explore age ranges (<50 vs >=50)\n",
    "- Using Mann-Whitney U test\n",
    "- Using the corpus CLAC and the speech task picture_description.\n",
    "- Two separate analyses for male and female, given that previously the decision was to derive different models for male and female subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8cd383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize read speech model:\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"partitioning/age/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\", #\"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"pic_description\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None, #\"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "            \n",
    "    # normalization\n",
    "    \"scale\": True,\n",
    "    \"multi_normalize\": True,\n",
    "    \"multi_normalize_conditions\": [\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "            \"gender\": [\"female\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "            \"gender\": [\"male\"]\n",
    "         }}\n",
    "    ],\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "speech_model = SpeechModel(config)\n",
    "\n",
    "\n",
    "# Get features and metadata:\n",
    "feats_names = speech_model.feature_names_lst\n",
    "meta = speech_model.meta_df.copy()\n",
    "feats = speech_model.feats_df.copy()\n",
    "\n",
    "\n",
    "# Run Mann-Whitney U test\n",
    "# male\n",
    "print (\" ------------ ANALYSIS FOR MALE  ------------\")\n",
    "features_that_should_have_distinct_ris_male = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"age\": (0, 49)}, {\"age\": (50, 100)},\n",
    "    cols_for_data_selection={\"gender\": [\"male\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_male), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_male),\n",
    "    \"features.\")\n",
    "\n",
    "# female\n",
    "print (\" ------------ ANALYSIS FOR FEMALE  ------------\")\n",
    "features_that_should_have_distinct_ris_female = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"age\": (0, 49)}, {\"age\": (50, 10000)},\n",
    "    cols_for_data_selection={\"gender\": [\"female\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_female), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_female),\n",
    "    \"features.\")\n",
    "\n",
    "print (\" ------------ COMBINING BOTH GENDERS ------------ \")\n",
    "feats_diff_ris_both_gender = np.unique(\n",
    "    np.concatenate((\n",
    "        features_that_should_have_distinct_ris_male, \n",
    "        features_that_should_have_distinct_ris_female)))\n",
    "print (\"Combining both genders:\", len(feats_diff_ris_both_gender))\n",
    "print (\"Number of features with p>= 0.001 (Combining both genders):\", len(feats_names) - len(feats_diff_ris_both_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2beaeb",
   "metadata": {},
   "source": [
    "### Explore speech tasks \n",
    "- Using Mann-Whitney U test\n",
    "- Using the corpus CLAC, and comparing the read speech task and the picture_description task.\n",
    "- Two separate analyses for male and female, given that previously the decision was to derive different models for male and female subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize read speech model:\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"partitioning/task/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"pic_description\", \"read_speech\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None, #\"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "            \n",
    "    # normalization\n",
    "    \"scale\": True,\n",
    "    \"multi_normalize\": True,\n",
    "    \"multi_normalize_conditions\": [\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "            \"gender\": [\"female\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "            \"gender\": [\"male\"]\n",
    "         }}\n",
    "    ],\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "speech_model = SpeechModel(config)\n",
    "\n",
    "\n",
    "# Get features and metadata:\n",
    "feats_names = FEATURE_NAMES[\"egemaps\"] + FEATURE_NAMES[\"praat\"]\n",
    "meta = speech_model.meta_df.copy()\n",
    "feats = speech_model.feats_df.copy()\n",
    "\n",
    "\n",
    "# Run Mann-Whitney U test\n",
    "# male\n",
    "print (\" ------------ ANALYSIS FOR MALE  ------------\")\n",
    "features_that_should_have_distinct_ris_male = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"task_type\": [\"pic_description\"]}, {\"task_type\": [\"read_speech\"]},\n",
    "    cols_for_data_selection={\"gender\": [\"male\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_male), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_male),\n",
    "    \"features.\")\n",
    "\n",
    "# female\n",
    "print (\" ------------ ANALYSIS FOR FEMALE  ------------\")\n",
    "features_that_should_have_distinct_ris_female = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"task_type\": [\"pic_description\"]}, {\"task_type\": [\"read_speech\"]},\n",
    "    cols_for_data_selection={\"gender\": [\"female\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_female), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_female),\n",
    "    \"features.\")\n",
    "\n",
    "print (\" ------------ COMBINING BOTH GENDERS ------------ \")\n",
    "feats_diff_ris_both_gender = np.unique(\n",
    "    np.concatenate((\n",
    "        features_that_should_have_distinct_ris_male, \n",
    "        features_that_should_have_distinct_ris_female)))\n",
    "print (\"Combining both genders:\", len(feats_diff_ris_both_gender))\n",
    "print (\"Number of features with p>= 0.001 (Combining both genders):\", len(feats_names) - len(feats_diff_ris_both_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf215cf",
   "metadata": {},
   "source": [
    "### Explore different corpora\n",
    "- Using Mann-Whitney U test\n",
    "- Using the speech task read speech, and comparing the corpus CLAC and TIMIT.\n",
    "- Two separate analyses for male and female, given that previously the decision was to derive different models for male and female subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize read speech model:\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"partitioning/corpus/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\", \"timit_concatenated\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"read_speech\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None, #\"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "            \n",
    "    # normalization\n",
    "    \"scale\": True,\n",
    "    \"multi_normalize\": True,\n",
    "    \"multi_normalize_conditions\": [\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "            \"gender\": [\"female\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "            \"gender\": [\"male\"]\n",
    "         }}\n",
    "    ],\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "speech_model = SpeechModel(config)\n",
    "\n",
    "\n",
    "# Get features and metadata:\n",
    "feats_names = FEATURE_NAMES[\"egemaps\"] + FEATURE_NAMES[\"praat\"]\n",
    "meta = speech_model.meta_df.copy()\n",
    "feats = speech_model.feats_df.copy()\n",
    "\n",
    "\n",
    "# Run Mann-Whitney U test\n",
    "# male\n",
    "print (\" ------------ ANALYSIS FOR MALE  ------------\")\n",
    "features_that_should_have_distinct_ris_male = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"origin_dataset\": [\"timit_concatenated\"]}, {\"origin_dataset\": [\"clac_healthy_w_vowel\"]},\n",
    "    cols_for_data_selection={\"gender\": [\"male\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_male), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_male),\n",
    "    \"features.\")\n",
    "\n",
    "# female\n",
    "print (\" ------------ ANALYSIS FOR FEMALE  ------------\")\n",
    "features_that_should_have_distinct_ris_female = feats_failling_mwut(\n",
    "    meta, feats, feats_names, {\"origin_dataset\": [\"timit_concatenated\"]}, {\"origin_dataset\": [\"clac_healthy_w_vowel\"]},\n",
    "    cols_for_data_selection={\"gender\": [\"female\"]})\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_female), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_female),\n",
    "    \"features.\")\n",
    "\n",
    "print (\" ------------ COMBINING BOTH GENDERS ------------ \")\n",
    "feats_diff_ris_both_gender = np.unique(\n",
    "    np.concatenate((\n",
    "        features_that_should_have_distinct_ris_male, \n",
    "        features_that_should_have_distinct_ris_female)))\n",
    "print (\"Combining both genders:\", len(feats_diff_ris_both_gender))\n",
    "print (\"Number of features with p>= 0.001 (Combining both genders):\", len(feats_names) - len(feats_diff_ris_both_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e25bea",
   "metadata": {},
   "source": [
    "**What if we normalized each corpus separately? In that case, can we combine different corpora under the same Reference Interval?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice how in this experiment the Speech Model will be created \n",
    "# without any normalization. We will perform the normalization \n",
    "# only inside the function feats_failling_mwut\n",
    "\n",
    "# Initialize read speech model:\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"partitioning/corpus_normalized/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "config = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\", \"timit_concatenated\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\"task_type\": [\"read_speech\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None, #\"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "            \n",
    "    # normalization\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model\n",
    "speech_model = SpeechModel(config)\n",
    "\n",
    "\n",
    "# Get features and metadata:\n",
    "feats_names = FEATURE_NAMES[\"egemaps\"] + FEATURE_NAMES[\"praat\"]\n",
    "meta = speech_model.meta_df.copy()\n",
    "feats = speech_model.feats_df.copy()\n",
    "\n",
    "\n",
    "# Run Mann-Whitney U test\n",
    "# male\n",
    "print (\" ------------ ANALYSIS FOR MALE  ------------\")\n",
    "features_that_should_have_distinct_ris_male = feats_failling_mwut(\n",
    "    meta, feats, feats_names, \n",
    "    {\"origin_dataset\": [\"timit_concatenated\"]}, \n",
    "    {\"origin_dataset\": [\"clac_healthy_w_vowel\"]},\n",
    "    cols_for_data_selection={\"gender\": [\"male\"]},\n",
    "    separate_scale = True,\n",
    ")\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_male), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_male),\n",
    "    \"features.\")\n",
    "\n",
    "# female\n",
    "print (\" ------------ ANALYSIS FOR FEMALE  ------------\")\n",
    "features_that_should_have_distinct_ris_female = feats_failling_mwut(\n",
    "    meta, feats, feats_names, \n",
    "    {\"origin_dataset\": [\"timit_concatenated\"]}, \n",
    "    {\"origin_dataset\": [\"clac_healthy_w_vowel\"]},\n",
    "    cols_for_data_selection={\"gender\": [\"female\"]},\n",
    "    separate_scale = True,\n",
    ")\n",
    "\n",
    "print (\n",
    "    len(features_that_should_have_distinct_ris_female), \n",
    "    \" features should have distinct RIs for each group, out of \",\n",
    "    len(feats_names))\n",
    "print (\n",
    "    \"On the other hand, we may derive the same RI for both groups for\",\n",
    "    len(feats_names) - len(features_that_should_have_distinct_ris_female),\n",
    "    \"features.\")\n",
    "\n",
    "print (\" ------------ COMBINING BOTH GENDERS ------------ \")\n",
    "feats_diff_ris_both_gender = np.unique(\n",
    "    np.concatenate((\n",
    "        features_that_should_have_distinct_ris_male, \n",
    "        features_that_should_have_distinct_ris_female)))\n",
    "print (\"Combining both genders:\", len(feats_diff_ris_both_gender))\n",
    "print (\"Number of features with p>= 0.001 (Combining both genders):\", len(feats_names) - len(feats_diff_ris_both_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feaf2e4",
   "metadata": {},
   "source": [
    "# 5. Deriving valid reference intervals\n",
    "\n",
    "We derive reference intervals via the non-parametric approach, using the 2.5 and 97.5 percentiles.\n",
    "To provide a confidence measure on the estimated RI, we derive 99% confidence intervals (CIs) for both the lower and upper limits of the RI via boostrapping.\n",
    "Data was resampled 1000 times to estimate the CIs. If the CI for any of the reference limits is larger than 20% of the RI, then the RI is not considered valid. \n",
    "After the bootsrapping, we fixed each RI as the outer bounds of the CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"/valid_intervals/\"\n",
    "\n",
    "# Define config for reference speech model\n",
    "reference_config_male = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\", \"voxceleb_annotated_usa_concatenated\", \"timit_concatenated\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/male/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"male\", #\"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": None, # {\"task_type\": [\"pic_description\"]},\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None,\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "    \n",
    "    # RIs:\n",
    "    \"use_50p_for_ri\": True,\n",
    "    \"use_outer_bound_of_CI\": False,\n",
    "            \n",
    "    # normalization -> we are not yet normalizing, only after separating the features by speech tasks.\n",
    "    #                  But we will use the multi_normalize_conditions when we normalize.\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": [\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "             \"origin_dataset\": [\"clac_healthy_w_vowel\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "             \"origin_dataset\": [\"voxceleb_annotated_usa_concatenated\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\": True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "             \"origin_dataset\": [\"timit_concatenated\"],\n",
    "         }}\n",
    "    ],\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# Initialize reference model for MALES\n",
    "print (\"-------------------------- MALES -------------------------------\")\n",
    "male_reference_speech_model = SpeechModel(reference_config_male)\n",
    "\n",
    "# Now let's separate features by speech task in the reference speech model\n",
    "_ = male_reference_speech_model.transform_feats_df_by_task(FEATURES_BY_TASK)\n",
    "\n",
    "# Normalize model:\n",
    "male_reference_speech_model.multi_normalize(reference_config_male[\"multi_normalize_conditions\"])\n",
    "\n",
    "# Get reference intervals via the non-parametric approach\n",
    "male_reference_speech_model.get_reference_intervals(method=\"np_ri\", return_friendly=False)\n",
    "\n",
    "ri_m = male_reference_speech_model.ri_df\n",
    "ri_m[\"valid_interval\"] = ri_m[\"valid_CI_lower_limit\"] & ri_m[\"valid_CI_upper_limit\"]\n",
    "invalid_ri_m = ri_m[ri_m.valid_interval == False].feature.values\n",
    "print (\"Invalid reference intervals via the non parametric approach:\")\n",
    "print (len(ri_m[ri_m.valid_interval == False]))\n",
    "print (invalid_ri_m)\n",
    "\n",
    "\n",
    "# Initialize reference model for FEMALES\n",
    "print (\"-------------------------- FEMALES -------------------------------\")\n",
    "reference_config_female = reference_config_male.copy()\n",
    "reference_config_female[\"sex\"] = \"female\"\n",
    "reference_config_female[\"output_dir\"] = main_output_dir +\"/ref_model/female/\"\n",
    "\n",
    "female_reference_speech_model = SpeechModel(reference_config_female)\n",
    "\n",
    "# Now let's separate features by speech task in the reference speech model\n",
    "_ = female_reference_speech_model.transform_feats_df_by_task(FEATURES_BY_TASK)\n",
    "\n",
    "# Normalize model:\n",
    "female_reference_speech_model.multi_normalize(reference_config_female[\"multi_normalize_conditions\"])\n",
    "\n",
    "# Get reference intervals via the non-parametric approach\n",
    "female_reference_speech_model.get_reference_intervals(method=\"np_ri\", return_friendly=False)\n",
    "\n",
    "ri_f = female_reference_speech_model.ri_df\n",
    "ri_f[\"valid_interval\"] = ri_f[\"valid_CI_lower_limit\"] & ri_f[\"valid_CI_upper_limit\"]\n",
    "invalid_ri_f = ri_f[ri_f.valid_interval == False].feature.values\n",
    "print (\"Invalid reference intervals via the non parametric approach:\")\n",
    "print (len(ri_f[ri_f.valid_interval == False]))\n",
    "print (invalid_ri_f)\n",
    "\n",
    "print (\"------------- Union of the ivalid features for both genders -------------\")\n",
    "invalid_ris = np.unique(np.concatenate([invalid_ri_m, invalid_ri_f]))\n",
    "print (invalid_ris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51bdc50",
   "metadata": {},
   "source": [
    "**Invalid Intervals:**\n",
    "\n",
    "'A#F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
    "'A#F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
    "'A#F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
    "'A#F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
    "'A#F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
    "'A#HNRdBACF_sma3nz_amean', \n",
    "'A#HNRdBACF_sma3nz_stddevNorm',\n",
    "'A#localabsoluteJitter', \n",
    "'A#ppq5Jitter',\n",
    "'Pic#F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
    "'Pic#ambiguous_ref_ratio', \n",
    "'Pic#discourse_marker_rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4922f3",
   "metadata": {},
   "source": [
    "# 6. Finally, the reference models \n",
    "One for male and one for female speakers.\n",
    "with all the decisions we have made so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "main_output_dir = MAIN_OUTPUT_DIR + \"experiments/\"\n",
    "drop_feats = FEATURE_NAMES[\"invalid_intervals\"] # we will exclude these from the analysis because they do not have valid RI's\n",
    "\n",
    "# Define config for reference speech model\n",
    "reference_config_male = {\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"/data_info/\",\n",
    "    \"datasets\": [\"clac_healthy_w_vowel\", \"voxceleb_annotated_usa_concatenated\", \"timit_concatenated\"], \n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir +\"/ref_model/male/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data\n",
    "    \"sex\": \"male\", #\"both\",  #\"male\", \"female\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": None,\n",
    "    \n",
    "    # outlier removal\n",
    "    \"outlier_removal\": True,\n",
    "    \"outlier_removal_conf\":{\n",
    "        \"from_id_list\": True,\n",
    "        \"outlier_id_list\": outlier_ids,\n",
    "        \"method\": None, #\"mcd_mahalanobis_dist\",\n",
    "        \"pca_oultier_limits\": None,\n",
    "        \"attribute_to_color_in_pca\": None, #\"origin_dataset\", #\"task_type\", #\"origin_dataset\", None\n",
    "        \"save_data_after\": False,\n",
    "    },\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "    \n",
    "    # RIs:\n",
    "    \"use_50p_for_ri\": False,\n",
    "    \"use_outer_bound_of_CI\": True,\n",
    "            \n",
    "    # normalization -> we are not yet normalizing, only below after separating features by speech task\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": [\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "             \"origin_dataset\": [\"clac_healthy_w_vowel\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "             \"origin_dataset\": [\"voxceleb_annotated_usa_concatenated\"],\n",
    "         }},\n",
    "        {\n",
    "        \"train_scaler\":True, \n",
    "        \"pretrained_scaler\":None, \n",
    "        \"cols_for_data_selection\":{\n",
    "             \"origin_dataset\": [\"timit_concatenated\"],\n",
    "         }}\n",
    "    ],\n",
    "    \"scaling_mode\": \"mean_0_std_1\", #None, \"min_max\", \"mean_0_std_1\", mean_1_std_1\n",
    "    \"train_scaler\": True,\n",
    "    \"save_data_after_normalize\": True,\n",
    "}\n",
    "\n",
    "######### MALE MODEL:\n",
    "\n",
    "# Initialize reference model\n",
    "ref_model_male = SpeechModel(reference_config_male)\n",
    "\n",
    "# Now let's separate features by speech task in the reference speech model\n",
    "_ = ref_model_male.transform_feats_df_by_task(FEATURES_BY_TASK, drop_features=drop_feats)\n",
    "\n",
    "# Normalize model:\n",
    "ref_model_male.multi_normalize(reference_config_male[\"multi_normalize_conditions\"])\n",
    "\n",
    "# Get reference intervals via the non-parametric approach\n",
    "RI_male_df = ref_model_male.get_reference_intervals(method=\"np_ri\", return_friendly=False)\n",
    "\n",
    "# Save reference intervals to output dir:\n",
    "ref_model_male.ri_df.to_csv(\n",
    "    reference_config_male[\"output_dir\"] + \"/ref_intervals.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "######### FEMALE MODEL:\n",
    "\n",
    "# Config\n",
    "reference_config_female = reference_config_male.copy()\n",
    "reference_config_female[\"sex\"] = \"female\"\n",
    "reference_config_female[\"output_dir\"] = main_output_dir +\"/ref_model/female/\"\n",
    "\n",
    "# Initialize reference model\n",
    "ref_model_female = SpeechModel(reference_config_female)\n",
    "\n",
    "# Now let's separate features by speech task in the reference speech model\n",
    "_ = ref_model_female.transform_feats_df_by_task(FEATURES_BY_TASK, drop_features=drop_feats)\n",
    "\n",
    "# Normalize model:\n",
    "ref_model_female.multi_normalize(reference_config_female[\"multi_normalize_conditions\"])\n",
    "\n",
    "# Get reference intervals via the non-parametric approach\n",
    "RI_female_df = ref_model_female.get_reference_intervals(method=\"np_ri\", return_friendly=False)\n",
    "\n",
    "# Save reference intervals to output dir:\n",
    "ref_model_female.ri_df.to_csv(\n",
    "    reference_config_female[\"output_dir\"] + \"/ref_intervals.csv\", \n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660bd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make reference plots\n",
    "\n",
    "# make reference plot for male speakers\n",
    "print (\"[INFO]: Gernerating radar plot...\")\n",
    "fig_m = ref_model_male.build_radar_plot(\n",
    "    plot_mean=True, save_fig=False,\n",
    "    plot_ri=True, mean_color=\"green\")\n",
    "\n",
    "# make reference plot for female speakers\n",
    "print (\"[INFO]: Gernerating radar plot...\")\n",
    "fig_f = ref_model_female.build_radar_plot(\n",
    "    plot_mean=True, save_fig=False,\n",
    "    plot_ri=True, mean_color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed37884",
   "metadata": {},
   "source": [
    "# 7. Comparison of the reference models with the datasets for diasease detection. \n",
    "We compare the reference intervals defined for the reference population \n",
    "with pc-gita (controls and patients of Parkinson's disease) and \n",
    "DementiaBank (controls and patients of Alzheimer's disease and depression).\n",
    "We compare male and female separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629badf3",
   "metadata": {},
   "source": [
    "####  Experiment in pc-gita vowel A, female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configs\n",
    "pcg_controls_config={\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"data_info/\",\n",
    "    \"datasets\": [\"pcgita_vowel\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir + \"pcgita_vowel/female/controls/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data:\n",
    "    \"sex\": \"female\",\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"exact\" : None,\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\n",
    "        \"pd_label\": [0],\n",
    "    },\n",
    "    # outlier removal:\n",
    "    \"outlier_removal\": False,   \n",
    "    \"outlier_removal_conf\":{},\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "    \n",
    "    # RIs:\n",
    "    \"use_50p_for_ri\": False,\n",
    "    \"use_outer_bound_of_CI\": True,\n",
    "    \n",
    "    # normalize\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": \"mean_0_std_1\",\n",
    "    \"train_scaler\": False,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "pcg_pd_config = pcg_controls_config.copy()\n",
    "pcg_pd_config[\"subselect_data\"] = {\n",
    "        \"pd_label\": [1],\n",
    "    }\n",
    "pcg_pd_config[\"output_dir\"] = main_output_dir + \"pcgita_vowel/female/pd/\"\n",
    "\n",
    "# run experiment\n",
    "summary_df, cm, disease_models = experiment(\n",
    "    ref_speech_model=ref_model_female, \n",
    "    control_config=pcg_controls_config, \n",
    "    disease_configs=[pcg_pd_config],\n",
    "    disease_names=[\"PD\"], \n",
    "    features_to_drop=drop_feats, \n",
    "    features_by_task=FEATURES_BY_TASK,\n",
    "    norm_strat=\"control_scaler\", #\"ref_scaler\", #\"none\", \n",
    "    ref_scaler=None\n",
    ")\n",
    "\n",
    "# Save reference intervals to output dir:\n",
    "summary_df = summary_df.sort_values(by=[\"prop_out_ri_over_subgroup#PD\"], ascending=False).round(3)\n",
    "summary_df.to_csv(\n",
    "    main_output_dir + \"pcgita_vowel/female/summary_results.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Preview\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438721c6",
   "metadata": {},
   "source": [
    "####  New experiment in pc-gita vowel A, male "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837afedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configs\n",
    "pcg_controls_config={\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"data_info/\",\n",
    "    \"datasets\": [\"pcgita_vowel\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir + \"pcgita_vowel/male/controls/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data:\n",
    "    \"sex\": \"male\",  #\"male\", \"female\", \"both\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"exact\" : None,\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\n",
    "        \"pd_label\": [0],\n",
    "    },\n",
    "    # outlier removal:\n",
    "    \"outlier_removal\": False,   \n",
    "    \"outlier_removal_conf\":{},\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "    \n",
    "    # RIs:\n",
    "    \"use_50p_for_ri\": False,\n",
    "    \"use_outer_bound_of_CI\": True,\n",
    "    \n",
    "    # normalize\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": \"mean_0_std_1\",\n",
    "    \"train_scaler\": False, #True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "pcg_pd_config = pcg_controls_config.copy()\n",
    "pcg_pd_config[\"subselect_data\"] = {\n",
    "        \"pd_label\": [1],\n",
    "    }\n",
    "pcg_pd_config[\"output_dir\"] = main_output_dir + \"pcgita_vowel/male/pd/\"\n",
    "\n",
    "# run experiment\n",
    "summary_df, cm, disease_models = experiment(\n",
    "    ref_speech_model=ref_model_male, \n",
    "    control_config=pcg_controls_config, \n",
    "    disease_configs=[pcg_pd_config],\n",
    "    disease_names=[\"PD\"], \n",
    "    features_to_drop=drop_feats, \n",
    "    features_by_task=FEATURES_BY_TASK,\n",
    "    norm_strat=\"control_scaler\", #\"ref_scaler\", #\"none\", \n",
    "    ref_scaler=None, #ref_scaler_male) #\n",
    ")\n",
    "\n",
    "# Save reference intervals to output dir:\n",
    "summary_df = summary_df.sort_values(by=[\"prop_out_ri_over_subgroup#PD\"], ascending=False).round(3)\n",
    "summary_df.to_csv(\n",
    "    main_output_dir + \"pcgita_vowel/male/summary_results.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Preview\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1706d0",
   "metadata": {},
   "source": [
    "####  New experiment in dementia bank, female "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configs\n",
    "db_controls_config={\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"data_info/\",\n",
    "    \"datasets\": [\"dementiabank\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\":  main_output_dir + \"db/female/controls/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data:\n",
    "    \"sex\": \"female\",  #\"male\", \"female\", \"both\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"exact\" : None,\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\n",
    "        \"transcript_diag\": [\"Control\"],\n",
    "        \"hamilton\": (0,7)\n",
    "    },\n",
    "    # outlier removal:\n",
    "    \"outlier_removal\": False,   \n",
    "    \"outlier_removal_conf\":{},\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "\n",
    "    # RIs:\n",
    "    \"use_50p_for_ri\": False,\n",
    "    \"use_outer_bound_of_CI\": True,\n",
    "    \n",
    "    # normalize\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": \"mean_0_std_1\",\n",
    "    \"train_scaler\": False, \n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# ad config\n",
    "ad_config = db_controls_config.copy()\n",
    "ad_config[\"subselect_data\"] = {\n",
    "        \"transcript_diag\": [\"ProbableAD\", \"Probable\"],\n",
    "        \"hamilton\": (0,7)\n",
    "    }\n",
    "ad_config[\"output_dir\"] = main_output_dir + \"db/female/ad/\"\n",
    "\n",
    "# depression config\n",
    "dep_config = db_controls_config.copy()\n",
    "dep_config[\"subselect_data\"] = {\n",
    "        \"transcript_diag\": [\"Control\"],\n",
    "        \"hamilton\": (8,10000)\n",
    "    }\n",
    "dep_config[\"output_dir\"] = main_output_dir + \"db/female/dep/\"\n",
    "\n",
    "# depression + ad config\n",
    "dep_ad_config = db_controls_config.copy()\n",
    "dep_ad_config[\"subselect_data\"] = {\n",
    "        \"transcript_diag\": [\"ProbableAD\", \"Probable\"],\n",
    "        \"hamilton\": (8,100000)\n",
    "    }\n",
    "dep_ad_config[\"output_dir\"] = main_output_dir + \"db/female/dep_ad/\"\n",
    "\n",
    "# run experiment\n",
    "summary_df, cm, disease_models = experiment(\n",
    "    ref_speech_model=ref_model_female, \n",
    "    control_config=db_controls_config, \n",
    "    disease_configs=[ad_config, dep_config, dep_ad_config],\n",
    "    disease_names=[\"AD\", \"Dep\", \"AD+Dep\"], \n",
    "    features_to_drop=drop_feats, \n",
    "    features_by_task=FEATURES_BY_TASK,\n",
    "    norm_strat=\"control_scaler\", #\"ref_scaler\", #\"none\", \n",
    "    ref_scaler=None\n",
    ")\n",
    "\n",
    "# Save reference intervals to output dir:\n",
    "summary_df = summary_df.sort_values(by=[\"prop_out_ri_over_subgroup#AD\"], ascending=False).round(3)\n",
    "summary_df.to_csv(\n",
    "    main_output_dir + \"db/female/summary_results.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Preview\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6f8ad",
   "metadata": {},
   "source": [
    "####  New experiment in dementia bank, male "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c739b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define configs\n",
    "db_controls_config={\n",
    "    \"feature_dir\" : ROOT + \"/features/\",\n",
    "    \"metadata_dir\": ROOT + \"data_info/\",\n",
    "    \"datasets\": [\"dementiabank\"],\n",
    "    \"features\": \"large_set\",\n",
    "    \"feature_columns_to_drop\": [],\n",
    "    \"output_dir\": main_output_dir + \"db/male/controls/\",\n",
    "    \"metadata_report\": False, #TODO\n",
    "    \"use_feat_subset\": None,\n",
    "    \n",
    "    # subselect data:\n",
    "    \"sex\": \"male\",  #\"male\", \"female\", \"both\"\n",
    "    \"age\": {  # allows specifying an age range\n",
    "        \"exact\" : None,\n",
    "        \"min\": None,  # either None or an int value\n",
    "        \"max\": None,  # either None or an int value\n",
    "    },\n",
    "    \"subselect_data\": {\n",
    "        \"transcript_diag\": [\"Control\"],\n",
    "        \"hamilton\": (0,7)\n",
    "    },\n",
    "    # outlier removal:\n",
    "    \"outlier_removal\": False,   \n",
    "    \"outlier_removal_conf\":{},\n",
    "    \"distinct_feats_for_outlier_detect\": True,\n",
    "\n",
    "    # RIs:\n",
    "    \"use_50p_for_ri\": False,\n",
    "    \"use_outer_bound_of_CI\": True,\n",
    "    \n",
    "    # normalize\n",
    "    \"scale\": False,\n",
    "    \"multi_normalize\": False,\n",
    "    \"multi_normalize_conditions\": None,\n",
    "    \"scaling_mode\": \"mean_0_std_1\",\n",
    "    \"train_scaler\": False, #True,\n",
    "    \"save_data_after_normalize\": False,\n",
    "}\n",
    "\n",
    "# ad config\n",
    "ad_config = db_controls_config.copy()\n",
    "ad_config[\"subselect_data\"] = {\n",
    "        \"transcript_diag\": [\"ProbableAD\", \"Probable\"],\n",
    "        \"hamilton\": (0,7)\n",
    "    }\n",
    "ad_config[\"output_dir\"] = main_output_dir + \"db/male/ad/\"\n",
    "\n",
    "# depression config\n",
    "dep_config = db_controls_config.copy()\n",
    "dep_config[\"subselect_data\"] = {\n",
    "        \"transcript_diag\": [\"Control\"],\n",
    "        \"hamilton\": (8,10000)\n",
    "    }\n",
    "dep_config[\"output_dir\"] = main_output_dir + \"db/male/dep/\"\n",
    "\n",
    "# depression + ad config\n",
    "dep_ad_config = db_controls_config.copy()\n",
    "dep_ad_config[\"subselect_data\"] = {\n",
    "        \"transcript_diag\": [\"ProbableAD\", \"Probable\"],\n",
    "        \"hamilton\": (8,100000)\n",
    "    }\n",
    "dep_ad_config[\"output_dir\"] = main_output_dir + \"db/male/dep_ad/\"\n",
    "\n",
    "# run experiment\n",
    "summary_df, cm, disease_models = experiment(\n",
    "    ref_speech_model=ref_model_male, \n",
    "    control_config=db_controls_config, \n",
    "    disease_configs=[ad_config, dep_config, dep_ad_config],\n",
    "    disease_names=[\"AD\", \"Dep\", \"AD+Dep\"], \n",
    "    features_to_drop=drop_feats, \n",
    "    features_by_task=FEATURES_BY_TASK,\n",
    "    norm_strat=\"control_scaler\", #\"ref_scaler\", #\"none\", \n",
    "    ref_scaler=None\n",
    ")\n",
    "\n",
    "# Save reference intervals to output dir:\n",
    "summary_df = summary_df.sort_values(by=[\"prop_out_ri_over_subgroup#AD\"], ascending=False).round(3)\n",
    "summary_df.to_csv(\n",
    "    main_output_dir + \"db/male/summary_results.csv\", \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# Preview\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
